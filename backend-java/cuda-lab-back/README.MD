# CUDA Image Lab - Backend

Backend de procesamiento de imÃ¡genes con aceleraciÃ³n GPU usando CUDA y FastAPI.

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n](#descripciÃ³n)
- [Requisitos](#requisitos)
- [InstalaciÃ³n](#instalaciÃ³n)
- [Arquitectura](#arquitectura)
- [API Endpoints](#api-endpoints)
- [Filtros Disponibles](#filtros-disponibles)
- [Ejemplos de Uso](#ejemplos-de-uso)
- [ParÃ¡metros CUDA](#parÃ¡metros-cuda)

---

## ğŸ¯ DescripciÃ³n

Sistema de procesamiento de imÃ¡genes en tiempo real con aceleraciÃ³n GPU NVIDIA CUDA. Implementa 4 filtros de convoluciÃ³n optimizados:

- **Prewitt**: DetecciÃ³n de bordes (primera derivada)
- **Laplacian**: DetecciÃ³n de bordes (segunda derivada) / LoG
- **Gaussian**: Suavizado con distribuciÃ³n gaussiana
- **Box Blur**: Suavizado rÃ¡pido con promedio simple

Cada filtro utiliza **convoluciÃ³n separable** para mÃ¡xima eficiencia: O(2N) vs O(NÂ²).

---

## ğŸ”§ Requisitos

### Hardware
- GPU NVIDIA con soporte CUDA (Compute Capability >= 3.0)
- MÃ­nimo 2GB VRAM recomendado

### Software
- Python 3.10+
- CUDA Toolkit 11.0+ 
- Visual Studio Build Tools (Windows)
- NVIDIA GPU Drivers actualizados

### Dependencias Python
```txt
fastapi
uvicorn
pycuda
numpy
pillow
pydantic
```

---

## ğŸ“¦ InstalaciÃ³n

### 1. Activar entorno virtual
```powershell
.\venv\Scripts\Activate.ps1
```

### 2. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 3. Verificar CUDA
```bash
nvidia-smi
```

### 4. Iniciar servidor
```bash
uvicorn app:app --host 0.0.0.0 --port 8000
```

O sin auto-reload:
```bash
python -c "import uvicorn; uvicorn.run('app:app', host='0.0.0.0', port=8000)"
```

---

## ğŸ—ï¸ Arquitectura

```
cuda-lab-back/
â”œâ”€â”€ app.py                      # FastAPI application (3 endpoints)
â”œâ”€â”€ convolution_service.py      # Main orchestrator (sync processing)
â”œâ”€â”€ progressive_convolution.py  # SSE streaming service (progressive)
â”œâ”€â”€ cuda_kernels.py             # Shared CUDA context + PTX compilation
â”œâ”€â”€ image_utils.py              # Image encoding/decoding
â”œâ”€â”€ filters/
â”‚   â”œâ”€â”€ __init__.py            # Filter router
â”‚   â”œâ”€â”€ prewitt.py             # Prewitt filter (5 CUDA kernels)
â”‚   â”œâ”€â”€ laplacian.py           # Laplacian/LoG (3 CUDA kernels)
â”‚   â”œâ”€â”€ gaussian.py            # Gaussian (4 CUDA kernels)
â”‚   â””â”€â”€ box_blur.py            # Box Blur (2 CUDA kernels)
â””â”€â”€ tests/
    â””â”€â”€ ...
```

**Principios de diseÃ±o:**
- âœ… Lazy CUDA initialization (contexto compartido)
- âœ… Cada filtro auto-contenido en `filters/`
- âœ… Grid dimensions auto-calculadas
- âœ… Kernels separables para eficiencia
- âœ… Manejo de errores robusto
- âœ… SSE streaming para visualizaciÃ³n progresiva

**MÃ³dulos Principales:**
- `app.py` - FastAPI endpoints (POST /convolve, POST /convolve-stream, GET /health)
- `convolution_service.py` - OrquestaciÃ³n de procesamiento estÃ¡ndar
- `progressive_convolution.py` - Procesamiento por chunks con SSE streaming
- `cuda_kernels.py` - Contexto CUDA compartido y compilaciÃ³n PTX
- `image_utils.py` - ConversiÃ³n base64 â†” NumPy â†” PIL
- `filters/` - Implementaciones especializadas de cada filtro

---

## ğŸŒ API Endpoints

### 1. Health Check

**Endpoint:** `GET /health`

**Respuesta:**
```json
{
  "status": "ok"
}
```

---

### 2. Aplicar Filtro de ConvoluciÃ³n

**Endpoint:** `POST /convolve`

**DescripciÃ³n:** Procesamiento estÃ¡ndar sÃ­ncrono de imagen con filtro CUDA.

**Request Body:**
```json
{
  "image_base64": "iVBORw0KGgoAAAANSUhEUgAA...",
  "filter": {
    "type": "prewitt | laplacian | gaussian | box_blur",
    "mask_size": 3,
    "gain": 8.0
  },
  "cuda_config": {
    "block_dim": [16, 16],
    "grid_dim": [29, 40]
  }
}
```

**Response:**
```json
{
  "status": "ok",
  "result_image_base64": "iVBORw0KGgoAAAANSUhEUgAA...",
  "execution_time_ms": 0.45,
  "kernel_time_ms": 0.42,
  "image_width": 640,
  "image_height": 480,
  "filter_used": "prewitt",
  "mask_size_used": 3,
  "block_dim": [16, 16],
  "grid_dim": [29, 40]
}
```

---

### 3. VisualizaciÃ³n Progresiva con SSE

**Endpoint:** `POST /convolve-stream`

**DescripciÃ³n:** Procesamiento progresivo con **Server-Sent Events (SSE)** que permite visualizar el procesamiento pÃ­xel por pÃ­xel en tiempo real.

**Request Body:** IdÃ©ntico a `/convolve`

**Response:** Stream de eventos SSE

```
data: {"progress": 5.18, "chunk": 1, "total_chunks": 193, "rows_processed": 32, "total_rows": 6162, "elapsed_ms": 234, "result_image_base64": "data:image/png;base64,...", "filter_used": "gaussian", "mask_size_used": 9}

data: {"progress": 10.36, "chunk": 2, "total_chunks": 193, "rows_processed": 64, "total_rows": 6162, "elapsed_ms": 468, "result_image_base64": "data:image/png;base64,...", "filter_used": "gaussian", "mask_size_used": 9}

...

data: {"progress": 100, "chunk": 193, "total_chunks": 193, "rows_processed": 6162, "total_rows": 6162, "elapsed_ms": 9650, "result_image_base64": "data:image/png;base64,...", "filter_used": "gaussian", "mask_size_used": 9, "completed": true}
```

**Â¿CÃ³mo Funciona?**

1. **DivisiÃ³n en Chunks**: La imagen se divide en franjas horizontales (default: 32 filas por chunk)
2. **Procesamiento Secuencial**: Cada chunk se procesa con el filtro CUDA completo
3. **TransmisiÃ³n Progresiva**: DespuÃ©s de procesar cada chunk, se envÃ­a el estado actual de la imagen vÃ­a SSE
4. **Delay Configurable**: Pausa de 50ms entre chunks para hacer la visualizaciÃ³n visible

**ParÃ¡metros de ConfiguraciÃ³n** (`progressive_convolution.py`):
```python
chunk_size: int = 32  # NÃºmero de filas por chunk (ajustable)
time.sleep(0.05)      # Delay entre chunks: 50ms (ajustable)
```

**Performance:**
- **Overhead**: ~50ms por chunk
- **Ejemplo**: Imagen 512Ã—512 con chunk_size=32 â†’ 16 chunks
- **Tiempo Total**: Tiempo procesamiento + (chunks Ã— delay)
  - Procesamiento normal: 100ms
  - Con streaming: 100ms + (16 Ã— 50ms) = 900ms total

**Casos de Uso:**
- ğŸ“š **Educativo**: DemostraciÃ³n de filtros de convoluciÃ³n en acciÃ³n
- ğŸ› **Debugging**: Identificar problemas en kernels CUDA observando artefactos visuales
- ğŸ¥ **Demo/PresentaciÃ³n**: Efecto visual impactante para audiencias no tÃ©cnicas

**Notas Importantes:**
- âœ… Cada chunk SÃ se procesa con el kernel CUDA real
- âœ… La imagen final es idÃ©ntica al endpoint `/convolve` normal
- âœ… Los tiempos de ejecuciÃ³n reflejan procesamiento real de GPU
- âš ï¸ La divisiÃ³n secuencial es artificial (GPU procesa en paralelo)
- âš ï¸ El delay es cosmÃ©tico (no refleja latencia real de GPU)

---

## ğŸ¨ Filtros Disponibles

### 1. ğŸ” Prewitt - DetecciÃ³n de Bordes Direccional

**DescripciÃ³n:** Detecta bordes usando gradientes en X e Y (primera derivada).

**Algoritmo:** Separable - 5 kernels CUDA
1. `box_vert_u8_to_f` - Suma vertical
2. `prewitt_x_from_V` - Gradiente X con pesos [-1, 0, +1]
3. `box_horiz_u8_to_f` - Suma horizontal  
4. `prewitt_y_from_H` - Gradiente Y con pesos [-1, 0, +1]
5. `combine_mag_to_gray` - Combina: |gx| + |gy| con gain

**ParÃ¡metros:**
- `mask_size`: TamaÃ±o del kernel (3, 5, 7, 9, 21...) - debe ser impar
- `gain`: Factor de realce de bordes (1.0-10.0+)
  - 1.0 - 3.0: Bordes sutiles
  - 4.0 - 6.0: Moderado
  - 7.0 - 10.0: Fuerte (default 8.0)
  - 10.0+: Muy intenso

**Ejemplo:**
```json
{
  "filter": {
    "type": "prewitt",
    "mask_size": 3,
    "gain": 8.0
  }
}
```

**Resultado:** Imagen con bordes resaltados en blanco sobre fondo oscuro.

---

### 2. âš¡ Laplacian - DetecciÃ³n de Bordes Omnidireccional

**DescripciÃ³n:** Detecta bordes usando segunda derivada (cambios rÃ¡pidos de intensidad).

**Modos:**

#### A) Laplacian ClÃ¡sico 3x3
```
[-1 -1 -1]
[-1  8 -1]
[-1 -1 -1]
```
**Uso:** `mask_size: 3`

#### B) Laplacian of Gaussian (LoG) NxN
Combina suavizado Gaussiano + Laplaciano para reducir ruido.

FÃ³rmula: `LoG(x,y) = -((rÂ² - 2ÏƒÂ²)/Ïƒâ´) * exp(-rÂ²/(2ÏƒÂ²))`  
donde `Ïƒ = N / 6`

**Algoritmo LoG:** 3 kernels CUDA
1. `conv_log_u8_to_f` - ConvoluciÃ³n NxN con kernel LoG
2. `f_abs_to_u8` - Valor absoluto + clamp [0,255]

**ParÃ¡metros:**
- `mask_size`: 
  - `3` â†’ Laplacian clÃ¡sico (rÃ¡pido)
  - `5, 7, 9, 21, 65...` â†’ LoG (mÃ¡s suave, menos ruido)

**Ejemplo:**
```json
{
  "filter": {
    "type": "laplacian",
    "mask_size": 9
  }
}
```

**Resultado:** Bordes finos en todas direcciones.

---

### 3. ğŸŒ«ï¸ Gaussian - Suavizado de Alta Calidad

**DescripciÃ³n:** Suavizado con distribuciÃ³n gaussiana 2D - reduce ruido preservando bordes.

**Algoritmo:** Separable - 4 kernels CUDA
1. `u8_to_f` - Convierte uint8 â†’ float
2. `gauss_horiz_f` - ConvoluciÃ³n horizontal 1D
3. `gauss_vert_f` - ConvoluciÃ³n vertical 1D
4. `f_to_u8` - Convierte float â†’ uint8

**FÃ³rmula Kernel 1D:**  
`G(x) = exp(-xÂ²/(2ÏƒÂ²))` normalizado, donde `Ïƒ = N / 6`

**ParÃ¡metros:**
- `mask_size`: TamaÃ±o del kernel (3, 5, 7, 9, 21, 61, 121...)
  - MÃ¡s grande = mÃ¡s suavizado
  - N=3: Suavizado mÃ­nimo
  - N=21: Suavizado medio
  - N=121: Suavizado intenso

**Ejemplo:**
```json
{
  "filter": {
    "type": "gaussian",
    "mask_size": 21
  }
}
```

**Resultado:** Imagen suavizada sin artefactos, preserva estructura.

---

### 4. ğŸ“¦ Box Blur - Suavizado RÃ¡pido

**DescripciÃ³n:** Promedio simple de vecinos - el mÃ¡s rÃ¡pido, calidad media.

**Algoritmo:** Separable - 2 kernels CUDA
1. `box_horiz_u8_to_f` - Suma horizontal
2. `box_vert_f_to_u8` - Suma vertical + normalizaciÃ³n (1/NÂ²)

**ParÃ¡metros:**
- `mask_size`: TamaÃ±o del kernel (3, 5, 7, 9, 21...)
  - N=3: Suavizado ligero
  - N=9: Suavizado moderado
  - N=21: Suavizado fuerte

**Ejemplo:**
```json
{
  "filter": {
    "type": "box_blur",
    "mask_size": 9
  }
}
```

**Resultado:** Imagen suavizada uniformemente (puede verse "blocky").

---

## ğŸ’¡ Ejemplos de Uso

### Ejemplo 1: Prewitt con Gain Ajustable

```json
{
  "image_base64": "/9j/4AAQSkZJRg...",
  "filter": {
    "type": "prewitt",
    "mask_size": 5,
    "gain": 6.0
  },
  "cuda_config": {
    "block_dim": [16, 16],
    "grid_dim": [1, 1]
  }
}
```

### Ejemplo 2: LoG 65x65 (Alta Calidad)

```json
{
  "image_base64": "/9j/4AAQSkZJRg...",
  "filter": {
    "type": "laplacian",
    "mask_size": 65
  },
  "cuda_config": {
    "block_dim": [16, 16],
    "grid_dim": [1, 1]
  }
}
```

### Ejemplo 3: Gaussian Suave

```json
{
  "image_base64": "/9j/4AAQSkZJRg...",
  "filter": {
    "type": "gaussian",
    "mask_size": 21
  },
  "cuda_config": {
    "block_dim": [32, 16],
    "grid_dim": [1, 1]
  }
}
```

### Ejemplo 4: Box Blur RÃ¡pido

```json
{
  "image_base64": "/9j/4AAQSkZJRg...",
  "filter": {
    "type": "box_blur",
    "mask_size": 9
  },
  "cuda_config": {
    "block_dim": [16, 16],
    "grid_dim": [1, 1]
  }
}
```

---

## âš™ï¸ ParÃ¡metros CUDA

### Block Dimensions (`block_dim`)

**DescripciÃ³n:** TamaÃ±o del bloque de threads CUDA.

**Valores recomendados:**
- `[16, 16]` - Balanceado (256 threads)
- `[32, 16]` - MÃ¡s threads en X (512 threads)
- `[8, 8]` - Menor uso (64 threads)

**LÃ­mites:**
- MÃ¡ximo: 1024 threads por bloque
- ComÃºn: 256-512 threads

### Grid Dimensions (`grid_dim`)

**DescripciÃ³n:** NÃºmero de bloques en la grid. **Se auto-calcula internamente.**

**FÃ³rmula:**
```
gridX = (image_width + blockX - 1) / blockX
gridY = (image_height + blockY - 1) / blockY
```

**Nota:** Puedes enviar `[1, 1]` - serÃ¡ recalculado automÃ¡ticamente.

---

## ğŸ“Š ComparaciÃ³n de Filtros

| Filtro | PropÃ³sito | Velocidad | Calidad | Separable | Kernels CUDA |
|--------|-----------|-----------|---------|-----------|--------------|
| **Prewitt** | Bordes direccionales | âš¡âš¡âš¡ | â­â­â­â­ | âœ… | 5 |
| **Laplacian** | Bordes omnidireccionales | âš¡âš¡âš¡ | â­â­â­â­ | âŒ | 3 |
| **Gaussian** | Suavizado calidad | âš¡âš¡ | â­â­â­â­â­ | âœ… | 4 |
| **Box Blur** | Suavizado rÃ¡pido | âš¡âš¡âš¡âš¡ | â­â­â­ | âœ… | 2 |

---

## ğŸ› SoluciÃ³n de Problemas

### Error: "CUDA initialization error"
- Verifica drivers NVIDIA: `nvidia-smi`
- Instala CUDA Toolkit
- Reinicia el sistema

### Error: "cuModuleLoadDataEx failed"
- Verifica Visual Studio Build Tools instalado
- Instala Windows SDK
- Reinicia terminal como administrador

### Imagen resultante en negro
- Verifica que la imagen base64 estÃ© correcta
- Revisa el `gain` en Prewitt (no uses valores muy altos)
- Prueba con `mask_size` mÃ¡s pequeÃ±o primero

### Rendimiento lento
- Aumenta `block_dim` a `[32, 16]`
- Usa kernels mÃ¡s pequeÃ±os (`mask_size: 3-9`)
- Verifica que no haya otros procesos usando la GPU

---

## ğŸ“ Notas TÃ©cnicas

### ConvoluciÃ³n Separable
Todos los filtros excepto Laplacian 3x3 usan convoluciÃ³n separable:
- Complejidad: O(2NÃ—WÃ—H) vs O(NÂ²Ã—WÃ—H)
- Ejemplo: N=21 â†’ 42 operaciones vs 441 operaciones por pixel

### Lazy CUDA Initialization
El contexto CUDA se inicializa solo cuando se necesita:
```python
_initialize_cuda()  # Llamado en el primer uso
```

### Manejo de Memoria
Cada filtro gestiona su propia memoria GPU:
- Prewitt: 6 buffers (gray, V, H, gx, gy, out)
- Laplacian 3x3: 2 buffers (gray, out)
- Laplacian LoG: 4 buffers (gray, K, tmpF, out)
- Gaussian: 6 buffers (u8, in, tmp, out, k1d, result)
- Box Blur: 3 buffers (in, out, tmp)

---

## ğŸš€ Roadmap

- [ ] Soporte para imÃ¡genes RGB (actualmente solo grayscale)
- [ ] Sobel filter
- [ ] Canny edge detection
- [ ] Bilateral filter
- [ ] Batch processing (mÃºltiples imÃ¡genes)
- [x] ~~WebSocket streaming~~ (implementado con SSE)
- [ ] ConfiguraciÃ³n dinÃ¡mica de chunk_size y delay para /convolve-stream
- [ ] Modo "instantÃ¡neo" vs "educativo" en visualizaciÃ³n progresiva
- [ ] MÃ©tricas de throughput (pÃ­xeles/segundo) en SSE

---

## ğŸ“š DocumentaciÃ³n Adicional

### Server-Sent Events (SSE) - Arquitectura

```
Frontend (React)                      Backend (FastAPI)
     â”‚                                       â”‚
     â”‚  POST /convolve-stream               â”‚
     â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
     â”‚  {image_base64, filter, cuda_config}  â”‚
     â”‚                                       â”‚
     â”‚                                  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
     â”‚                                  â”‚ Divide  â”‚
     â”‚                                  â”‚ imagen  â”‚
     â”‚                                  â”‚ chunks  â”‚
     â”‚                                  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
     â”‚                                       â”‚
     â”‚  SSE: data: {progress: 5%, ...}  â”Œâ”€â”€â”€â–¼â”€â”€â”€â”
     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤Processâ”‚
     â”‚                                  â”‚Chunk 1â”‚
     â”‚                                  â””â”€â”€â”€â”¬â”€â”€â”€â”˜
     â”‚                                      â”‚
     â”‚  SSE: data: {progress: 10%, ...} â”Œâ”€â”€â–¼â”€â”€â”€â”
     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤Processâ”‚
     â”‚                                  â”‚Chunk 2â”‚
     â”‚                                  â””â”€â”€â”€â”¬â”€â”€â”€â”˜
     â”‚                                      â”‚
     â”‚                ...                  ...
     â”‚                                      â”‚
     â”‚  SSE: data: {completed: true}    â”Œâ”€â”€â–¼â”€â”€â”€â”
     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ Done â”‚
     â”‚                                  â””â”€â”€â”€â”€â”€â”€â”˜
```

### Por quÃ© SSE en lugar de WebSockets?

| CaracterÃ­stica | SSE | WebSockets |
|---------------|-----|------------|
| **DirecciÃ³n** | Unidireccional (servidor â†’ cliente) | Bidireccional |
| **Protocolo** | HTTP/1.1, HTTP/2 | WS:// (upgrade de HTTP) |
| **ReconexiÃ³n** | AutomÃ¡tica por el navegador | Manual (requiere lÃ³gica) |
| **Simplicidad** | Fetch API nativa | Requiere biblioteca adicional |
| **Uso de recursos** | Menor overhead | Mayor overhead |
| **Caso de uso** | Streaming de progreso, notificaciones | Chat, colaboraciÃ³n en tiempo real |

Para visualizaciÃ³n progresiva, **SSE es ideal** porque:
- âœ… Solo necesitamos servidor â†’ cliente (progreso)
- âœ… ReconexiÃ³n automÃ¡tica si hay error de red
- âœ… Funciona sobre HTTP estÃ¡ndar (no requiere WS upgrade)
- âœ… MÃ¡s simple de implementar y debuggear

---

## ğŸ“„ Licencia

MIT License

---

## ğŸ‘¥ Contribuciones

Desarrollado como proyecto acadÃ©mico de CUDA Parallel Computing.
